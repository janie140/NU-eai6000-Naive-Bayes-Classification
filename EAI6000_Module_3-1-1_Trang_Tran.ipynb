{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e22c16-68b6-4879-9256-6e3030754591",
   "metadata": {},
   "source": [
    "# Module 3: Naive Bayes' Classificiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f2bcd6-713e-43bf-8351-98b69b839160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5fdad-679d-4a19-b9f9-58555a701788",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47166d0-3a0b-4566-adb0-602355f43f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shown in class\n",
    "\n",
    "data = [['M', 1, 0],\n",
    "        ['M', 1, 1],\n",
    "        ['R', 1, 1],\n",
    "        ['R', 1, 1],\n",
    "        ['M', 0, 1],\n",
    "        ['M', 1, 1],\n",
    "        ['R', 0, 1],\n",
    "        ['R', 1, 0],\n",
    "        ['R', 0, 0]]\n",
    "\n",
    "df_MR = pd.DataFrame(data, columns = ['label', 'f1', 'f2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad4d6bd-f07e-401a-992a-ed023a183876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  f1  f2\n",
       "0     M   1   0\n",
       "1     M   1   1\n",
       "2     R   1   1\n",
       "3     R   1   1\n",
       "4     M   0   1\n",
       "5     M   1   1\n",
       "6     R   0   1\n",
       "7     R   1   0\n",
       "8     R   0   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed555a9a-5aa0-40df-833a-95002e004a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get compute P(M|f1)\n",
    "\n",
    "def get_prob_M_f1(df, f1):\n",
    "    \n",
    "    # total number of datapoints\n",
    "    n_all = df.shape[0]\n",
    "    \n",
    "    # total # of mammals in the dataset\n",
    "    n_M = df[df.label=='M'].shape[0]\n",
    "    \n",
    "    # total # of reptiles\n",
    "    n_R = df[df.label=='R'].shape[0]\n",
    "    \n",
    "    # total # of mammals with the given feature value\n",
    "    n_M_f1 = df[(df.label=='M') & (df.f1==f1)].shape[0]\n",
    "    \n",
    "    # total # of reptiles with the given feature value\n",
    "    n_R_f1 = df[(df.label=='R') & (df.f1==f1)].shape[0]\n",
    "    \n",
    "    # compute terms in Bayes' formula\n",
    "    prob_M    = n_M/n_all\n",
    "    prob_f1_M = n_M_f1/n_M\n",
    "\n",
    "    prob_R    = n_R/n_all\n",
    "    prob_f1_R = n_R_f1/n_R\n",
    "    \n",
    "    prob_M_f1 = prob_M * prob_f1_M / ((prob_M * prob_f1_M) + (prob_R*prob_f1_R))\n",
    "    \n",
    "    return prob_M_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0529f3b7-1e57-465d-94b1-2cbabd042320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_M_f1(df_MR, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3b89c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_M_f1(df_MR, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdcf31",
   "metadata": {},
   "source": [
    "# Calculations by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfacd75",
   "metadata": {},
   "source": [
    "Q1: Consider the case of only one feature, f2 = 0. What is the probability that this is a reptile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a7194",
   "metadata": {},
   "source": [
    "Hypothesis (H): This animal is a reptile (R)\n",
    "Evidence (E): f2 = 0 \n",
    "\n",
    "P(H) = 5/9\n",
    "P(E/H) = 2/5\n",
    "P(-H) = 1 - P(H) = 4/9\n",
    "P(E/-H)) = 1/4\n",
    "\n",
    "P(H/E) = P(H)*P(E/H)/ (P(H)*P(E/H) + P(-H)*P(E/-H)) = 5/9*2/5 / (5/9*2/5 + 4/9*1/4) = 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4280c4",
   "metadata": {},
   "source": [
    "Q2. In the case where you have two feature values, (f1 = 1, f2 = 0), what is the probability that this comes from a reptile?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51601a",
   "metadata": {},
   "source": [
    "Hypothesis (H): This animal is a reptile (R)\n",
    "Evidence (E): f1 = 1 and f2 = 0 \n",
    "\n",
    "P(H) = 5/9\n",
    "P(E/H) = 1/5\n",
    "P(-H) = 1 - P(H) = 4/9\n",
    "P(E/-H)) = 1/4\n",
    "\n",
    "P(H/E) = P(H)*P(E/H)/ (P(H)*P(E/H) + P(-H)*P(E/-H)) = 5/9*1/5 / (5/9*1/5 + 4/9*1/4) = 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07990a9d",
   "metadata": {},
   "source": [
    "## <font color = 'green'> Python coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb464b4",
   "metadata": {},
   "source": [
    "Q3. Write an equivalent function, get_prob_R_f1(df, f1) to get the probability of a reptile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40cf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get compute P(R|f1)\n",
    "\n",
    "def get_prob_R_f1(df, f1):\n",
    "    # total number of datapoints\n",
    "    n_all = df.shape[0]\n",
    "    \n",
    "    # total # of mammals in the dataset\n",
    "    n_M = df[df.label=='M'].shape[0]\n",
    "    \n",
    "    # total # of reptiles\n",
    "    n_R = df[df.label=='R'].shape[0]\n",
    "    \n",
    "    # total # of mammals with the given feature value\n",
    "    n_M_f1 = df[(df.label=='M') & (df.f1==f1)].shape[0]\n",
    "    \n",
    "    # total # of reptiles with the given feature value\n",
    "    n_R_f1 = df[(df.label=='R') & (df.f1==f1)].shape[0]\n",
    "    \n",
    "    # compute terms in Bayes' formula\n",
    "    prob_M    = n_M/n_all\n",
    "    prob_f1_M = n_M_f1/n_M\n",
    "\n",
    "    prob_R    = n_R/n_all\n",
    "    prob_f1_R = n_R_f1/n_R\n",
    "    \n",
    "    prob_R_f1 = prob_R * prob_f1_R / ((prob_R * prob_f1_R) + (prob_M * prob_f1_M))\n",
    "    \n",
    "    return prob_R_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87d48b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_R_f1(df_MR, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3dfcb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_R_f1(df_MR, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4931c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get compute P(R|f2)\n",
    "\n",
    "def get_prob_R_f2(df, f2):\n",
    "    # total number of datapoints\n",
    "    n_all = df.shape[0]\n",
    "    \n",
    "    # total # of mammals in the dataset\n",
    "    n_M = df[df.label=='M'].shape[0]\n",
    "    \n",
    "    # total # of reptiles\n",
    "    n_R = df[df.label=='R'].shape[0]\n",
    "    \n",
    "    # total # of mammals with the given feature value\n",
    "    n_M_f2 = df[(df.label=='M') & (df.f2==f2)].shape[0]\n",
    "    \n",
    "    # total # of reptiles with the given feature value\n",
    "    n_R_f2 = df[(df.label=='R') & (df.f2==f2)].shape[0]\n",
    "    \n",
    "    # compute terms in Bayes' formula\n",
    "    prob_M    = n_M/n_all\n",
    "    prob_f2_M = n_M_f2/n_M\n",
    "\n",
    "    prob_R    = n_R/n_all\n",
    "    prob_f2_R = n_R_f2/n_R\n",
    "    \n",
    "    prob_R_f2 = prob_R * prob_f2_R / ((prob_R * prob_f2_R) + (prob_M * prob_f2_M))\n",
    "    \n",
    "    return prob_R_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b102f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob_R_f2(df_MR, 0) # Equal to the result of Q1: 2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864a767",
   "metadata": {},
   "source": [
    "Q4: Write a function get_prob_MR(df,f1,f2) to compute the ratio of the probabilities of the two labels, as expressed in equation (6). This function should return 'M' or 'R', depending on the value of the ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3131d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fractions\n",
    "\n",
    "# function to get compute P(MR|f1,f2)\n",
    "def classify_MR(df, f1, f2):\n",
    "    # total number of datapoints\n",
    "    n_all = df.shape[0]\n",
    "    \n",
    "    # total # of mammals in the dataset\n",
    "    n_M = df[df.label=='M'].shape[0]\n",
    "    \n",
    "    # total # of reptiles\n",
    "    n_R = df[df.label=='R'].shape[0]\n",
    "    \n",
    "    # total # of mammals with the given feature values\n",
    "    n_M_f1f2 = df[(df.label=='M') & (df.f1==f1) & (df.f2==f2)].shape[0]\n",
    "    \n",
    "    # total # of reptiles with the given feature values\n",
    "    n_R_f1f2 = df[(df.label=='R') & (df.f1==f1) & (df.f2==f2)].shape[0]\n",
    "    \n",
    "    # compute terms in Bayes' formula\n",
    "    prob_M = fractions.Fraction(n_M, n_all)\n",
    "    prob_f1f2_M = fractions.Fraction(n_M_f1f2, n_M) \n",
    "\n",
    "    prob_R = fractions.Fraction(n_R, n_all)\n",
    "    prob_f1f2_R = fractions.Fraction(n_R_f1f2, n_R)\n",
    "    \n",
    "    # compute the ratio of probabilities\n",
    "    # Naive Bayes' Classification formula\n",
    "    ratio = (prob_M * prob_f1f2_M)/ (prob_R * prob_f1f2_R) \n",
    "\n",
    "    # return 'M' if the ratio is greater than 1, else return 'R'\n",
    "    if ratio > 1:\n",
    "        return 'M'\n",
    "    elif ratio < 1:\n",
    "        return 'R'\n",
    "    # In the case of equal probabilities of two labels\n",
    "    else:\n",
    "        # If the ratio is exactly 1\n",
    "        return 'Equal probabilities of M and R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b42ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Equal probabilities of M and R'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_MR(df_MR, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37618637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_MR(df_MR, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a25224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Equal probabilities of M and R'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_MR(df_MR, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4153f2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Equal probabilities of M and R'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_MR(df_MR, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ba5ad",
   "metadata": {},
   "source": [
    "Q5. Are there cases where the predicted label for a given pair of (f1, f2) does not match the actual label in the dataframe? If so, why? If not, is that always guaranteed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b922b42",
   "metadata": {},
   "source": [
    "Due to the equal probabilities of the two labels in some cases, misclassifications can occur if we define the function to randomly select one of the labels. In the function above, I specify that the return value for these cases is \"Equal probabilities of M and R\".\n",
    "\n",
    "For the other case (f1 = f2 = 0), the predicted label matches the actual one in the DataFrame. It is not always guaranteed, especially with more data, because the predicted result is based solely on the label with the higher probability, not a 100% probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb8fca-c5aa-456d-b8f2-558fae2c10b7",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c877838-1d7d-41fc-abc1-0f0755baa2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>ApprovalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income  CreditScore  ApprovalStatus\n",
       "0         1            1               1\n",
       "1         1            0               1\n",
       "2         0            1               1\n",
       "3         0            0               1\n",
       "4         0            0               1\n",
       "..      ...          ...             ...\n",
       "684       0            0               0\n",
       "685       1            1               0\n",
       "686       0            0               0\n",
       "687       1            0               0\n",
       "688       0            0               0\n",
       "\n",
       "[689 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "df_cc = pd.read_csv('cc_approvals-1-1.csv')\n",
    "df_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e893c",
   "metadata": {},
   "source": [
    "Q7. What are all the possibilities of values of Income and CreditScore that a person can have? Write them in a table. How many distinct pairs of values are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cdf7f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>CreditScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  CreditScore\n",
       "0       1            0\n",
       "1       1            1\n",
       "2       0            1\n",
       "3       0            0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are four distinct pairs of values of Income and CreditScore in total.\n",
    "data = [[1, 0],\n",
    "        [1, 1],\n",
    "        [0, 1],\n",
    "        [0, 0]]\n",
    "\n",
    "df_Q7 = pd.DataFrame(data, columns = ['Income', 'CreditScore'])\n",
    "df_Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a9762",
   "metadata": {},
   "source": [
    "Q8. Modify the function in (4) to take df_cc, Income, and CreditScore as input and return a 1 or 0, corresponding to the approval status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8edd8caa-d73a-4913-ad23-03b254d2cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fractions\n",
    "\n",
    "# function to get compute P(Approval|Income, CreditScore)\n",
    "def approval_status(df, f1, f2):\n",
    "    # total number of datapoints\n",
    "    n_all = df.shape[0]\n",
    "    \n",
    "    # total # of approved cc in the dataset\n",
    "    n_approved = df[df.ApprovalStatus==1].shape[0]\n",
    "    \n",
    "    # total # of declined cc\n",
    "    n_declined = df[df.ApprovalStatus==0].shape[0]\n",
    "    \n",
    "    # total # of approved cc with the given feature values\n",
    "    n_approved_f1f2 = df[(df.ApprovalStatus==1) & (df.Income==f1) & (df.CreditScore==f2)].shape[0]\n",
    "    \n",
    "    # total # of declined cc with the given feature values\n",
    "    n_declined_f1f2 = df[(df.ApprovalStatus==0) & (df.Income==f1) & (df.CreditScore==f2)].shape[0]\n",
    "    \n",
    "    # compute terms in Bayes' formula\n",
    "    prob_approved = fractions.Fraction(n_approved, n_all)\n",
    "    prob_f1f2_approved = fractions.Fraction(n_approved_f1f2, n_approved) \n",
    "\n",
    "    prob_declined = fractions.Fraction(n_declined, n_all)\n",
    "    prob_f1f2_declined = fractions.Fraction(n_declined_f1f2, n_declined)\n",
    "    \n",
    "    # compute the ratio of probabilities\n",
    "    # Naive Bayes' Classification formula\n",
    "    ratio = (prob_approved * prob_f1f2_approved)/ (prob_declined * prob_f1f2_declined) \n",
    "\n",
    "    # return '1' if the ratio is greater than 1, else return '0'\n",
    "    if ratio > 1:\n",
    "        return '1'\n",
    "    elif ratio < 1:\n",
    "        return '0'\n",
    "    # In the case of equal probabilities of two labels\n",
    "    else:\n",
    "        # If the ratio is exactly 1\n",
    "        return 'Equal probabilities of 1 and 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df752e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>ApprovalStatus_NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Income  CreditScore ApprovalStatus_NB\n",
       "0       1            0                 0\n",
       "1       1            1                 1\n",
       "2       0            1                 1\n",
       "3       0            0                 0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "new_data = [[1, 0, approval_status(df_cc, 1, 0)],\n",
    "        [1, 1, approval_status(df_cc, 1, 1)],\n",
    "        [0, 1, approval_status(df_cc, 0, 1)],\n",
    "        [0, 0, approval_status(df_cc, 0, 0)]]\n",
    "\n",
    "df_nb = pd.DataFrame(new_data, columns = ['Income', 'CreditScore', 'ApprovalStatus_NB'])\n",
    "df_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63e49f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>ApprovalStatus</th>\n",
       "      <th>ApprovalStatus_NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income  CreditScore  ApprovalStatus ApprovalStatus_NB\n",
       "0         1            1               1                 1\n",
       "1         1            1               1                 1\n",
       "2         1            1               1                 1\n",
       "3         1            1               1                 1\n",
       "4         1            1               1                 1\n",
       "..      ...          ...             ...               ...\n",
       "684       0            0               0                 0\n",
       "685       0            0               0                 0\n",
       "686       0            0               0                 0\n",
       "687       0            0               0                 0\n",
       "688       0            0               0                 0\n",
       "\n",
       "[689 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "df_cc = df_cc.merge(df_nb, on = ['Income', 'CreditScore'])\n",
    "df_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63b3e5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income                int64\n",
       "CreditScore           int64\n",
       "ApprovalStatus        int64\n",
       "ApprovalStatus_NB    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad08c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc['ApprovalStatus_NB'] = df_cc['ApprovalStatus_NB'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a93c3",
   "metadata": {},
   "source": [
    "Q11. The overall accuracy of correctly predicting the ApprovalStatus can be obtained by counting the number of rows in the updated df_cc table where ApprovalStatus == ApprovalStatus_NB divided by the total number of rows. What is the overall accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da5bd391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.7358490566037735\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows where ApprovalStatus == ApprovalStatus_NB\n",
    "correct_pred = df_cc[df_cc['ApprovalStatus'] == df_cc['ApprovalStatus_NB']].shape[0]\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "n_rows = df_cc.shape[0]\n",
    "accuracy = correct_pred / n_rows\n",
    "\n",
    "print(\"Overall Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc2df2",
   "metadata": {},
   "source": [
    "Q12. Explain the value of the accuracy - is it what you would expect it to be? if so, why? if not, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d01e8f",
   "metadata": {},
   "source": [
    "The accuracy is quite high (close to 1) so it indicates that the model's predictions match the actual ApprovalStatus values for a large portion of the dataset. This suggests that the model is performing well in predicting credit card approvals based on the two provided features (Income & CreditScore)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
